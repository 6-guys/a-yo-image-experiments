{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUDrrtyg53Ah"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Conv2D, Flatten, Reshape, Conv2DTranspose, UpSampling2D\n",
        "from tensorflow.keras.layers import Layer, ConvLSTM2D, BatchNormalization, Concatenate, TimeDistributed, Dropout\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG19\n",
        "import imageio\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG19을 통한 특징 추출기 정의 (block3_conv3 레이어 사용)\n",
        "vgg = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "vgg.trainable = False\n",
        "feature_extractor = Model(inputs=vgg.input, outputs=vgg.get_layer(\"block3_conv3\").output)\n",
        "tf.random.set_seed(None)  # None으로 설정하여 매번 다른 난수 생성"
      ],
      "metadata": {
        "id": "5DwApA603gti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KL 가중치 점진적 증가를 위한 스케줄링 콜백\n",
        "class KLDivergenceWeightScheduler(Callback):\n",
        "    def __init__(self, start_weight=1e-5, max_weight=1e-2, increase_rate=1e-5):\n",
        "        super(KLDivergenceWeightScheduler, self).__init__()\n",
        "        self.weight = start_weight\n",
        "        self.max_weight = max_weight\n",
        "        self.increase_rate = increase_rate\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # 점진적으로 kl_loss_weight를 증가시키고 최대 한도에서 제한\n",
        "        if self.weight < self.max_weight:\n",
        "            self.weight += self.increase_rate\n",
        "        else:\n",
        "            self.weight = self.max_weight"
      ],
      "metadata": {
        "id": "eGO4jg_yZZFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 설정: 잠재 공간 크기 및 이미지 크기 조정\n",
        "latent_dim = 32 # 잠재 공간 크기를 32로 조정\n",
        "fixed_length = 10\n",
        "img_size = (128, 128)  # 이미지 크기를 128x128로 조정"
      ],
      "metadata": {
        "id": "TPBmdxVW6McI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_gif(gif_path, img_size=(128, 128)):\n",
        "    gif = Image.open(gif_path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            frame = gif.convert('RGB').resize(img_size)\n",
        "            frame_np = np.array(frame) / 255.0  # [0, 1] 범위로 정규화\n",
        "            frames.append(frame_np)\n",
        "            gif.seek(gif.tell() + 1)\n",
        "    except EOFError:\n",
        "        pass\n",
        "    frames = np.array(frames)\n",
        "\n",
        "    x = frames[0]  # 첫 번째 프레임\n",
        "    y = frames[1:fixed_length+1] if len(frames) > fixed_length else np.pad(\n",
        "        frames[1:], ((0, fixed_length - len(frames[1:])), (0, 0), (0, 0), (0, 0)), mode='constant')\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "x-0fPcc41f2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GIF 파일로부터 x, y 데이터셋 생성 함수\n",
        "def load_gif_dataset(gif_paths, img_size=(128, 128)):\n",
        "    x_data, y_data = [], []\n",
        "    for gif_path in gif_paths:\n",
        "        x, y = preprocess_gif(gif_path, img_size)\n",
        "        x_data.append(x)\n",
        "        y_data.append(y)\n",
        "    return np.array(x_data), np.array(y_data)"
      ],
      "metadata": {
        "id": "lbQeYw8b6FfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_encoder(img_shape=(img_size[0], img_size[1], 3), latent_dim=32):\n",
        "    input_img = Input(shape=img_shape, name='image_input')\n",
        "\n",
        "    # Conv 레이어와 드롭아웃을 사용하여 공간적 특징을 추출\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(input_img)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)  # 드롭아웃 추가\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)  # 드롭아웃 추가\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)  # 드롭아웃 추가\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)  # 드롭아웃 추가\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # 잠재 벡터 추출\n",
        "    z_mean = Dense(latent_dim, name=\"z_mean\")(x)\n",
        "    z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "    # 노이즈 주입을 통해 잠재 벡터의 다양성 증가\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim), mean=0.0, stddev=1.0)\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon  # 노이즈 추가로 다양성 증가\n",
        "\n",
        "    z = Lambda(sampling, output_shape=(latent_dim,), name=\"z\")([z_mean, z_log_var])\n",
        "    encoder = Model(input_img, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "    return encoder"
      ],
      "metadata": {
        "id": "fh76YzWd6Onj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_decoder(latent_dim, output_shape=(fixed_length, img_size[0], img_size[1], 3)):\n",
        "    decoder_input = Input(shape=(latent_dim,), name='decoder_input')\n",
        "\n",
        "    # 잠재 벡터 확장 및 재구성 단계\n",
        "    # 여기서 output_shape의 크기에 맞추어 32x32x128 형태로 맞춥니다.\n",
        "    units = fixed_length * 16 * 16 * 128  # 원하는 크기 맞춤\n",
        "    x = Dense(units, activation='relu')(decoder_input)\n",
        "    x = Reshape((fixed_length, 16, 16, 128))(x)\n",
        "\n",
        "    # ConvLSTM2D 레이어를 사용하여 시간적 특징을 추출\n",
        "    x = ConvLSTM2D(128, (3, 3), activation='relu', padding='same', return_sequences=True)(x)\n",
        "    x = ConvLSTM2D(64, (3, 3), activation='relu', padding='same', return_sequences=True)(x)\n",
        "\n",
        "    # 업샘플링과 Conv2DTranspose를 사용하여 원하는 출력 크기까지 확장\n",
        "    x = TimeDistributed(UpSampling2D(size=(2, 2)))(x)\n",
        "    x = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\n",
        "    x = TimeDistributed(UpSampling2D(size=(2, 2)))(x)\n",
        "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'))(x)\n",
        "    x = TimeDistributed(UpSampling2D(size=(2, 2)))(x)\n",
        "    x = TimeDistributed(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))(x)\n",
        "\n",
        "    decoder = Model(decoder_input, x, name=\"decoder\")\n",
        "    return decoder\n"
      ],
      "metadata": {
        "id": "B-K0ebY06P2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(CVAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.kl_weight = tf.Variable(1e-6, trainable=False)\n",
        "        self.noise_scale = tf.Variable(1.0, trainable=False)\n",
        "\n",
        "        # VGG 모델의 특정 레이어를 선택\n",
        "        vgg = VGG19(include_top=False, weights=\"imagenet\")\n",
        "        self.perceptual_model = Model(inputs=vgg.input, outputs=vgg.get_layer(\"block5_conv2\").output)\n",
        "        self.perceptual_model.trainable = False  # VGG 모델의 가중치는 고정\n",
        "\n",
        "        # Perceptual loss 계산을 위한 Mean Squared Error 객체 생성\n",
        "        self.mse_loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        z = Dropout(0.3)(z)  # 추가된 Dropout\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            # 노이즈 스케일을 조절하며 다양성 증가\n",
        "            z_mean, z_log_var, z = self.encoder(x)\n",
        "            noise = tf.random.normal(shape=tf.shape(z), mean=0.0, stddev=self.noise_scale)\n",
        "            z = z + noise  # 노이즈 추가\n",
        "            reconstruction = self.decoder(z)\n",
        "\n",
        "            # Perceptual Loss 계산\n",
        "            batch_size, time_steps, height, width, channels = reconstruction.shape\n",
        "            y_reshaped = tf.reshape(y, [batch_size * time_steps, height, width, channels])\n",
        "            reconstruction_reshaped = tf.reshape(reconstruction, [batch_size * time_steps, height, width, channels])\n",
        "            y_features = self.perceptual_model(y_reshaped)\n",
        "            reconstruction_features = self.perceptual_model(reconstruction_reshaped)\n",
        "            perceptual_loss = self.mse_loss(y_features, reconstruction_features)\n",
        "\n",
        "            # KL Loss 계산 (β-VAE와 KL-Annealing 적용)\n",
        "            beta = 4.0\n",
        "            kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = beta * tf.clip_by_value(kl_loss, 0, 5000)\n",
        "\n",
        "            # 총 손실 계산 및 KL 가중치 증가\n",
        "            total_loss = perceptual_loss + self.kl_weight * kl_loss\n",
        "            self.add_loss(total_loss)  # <-- total_loss를 모델의 손실로 추가\n",
        "            self.kl_weight.assign(tf.minimum(self.kl_weight + 1e-7, 1e-3))\n",
        "            self.noise_scale.assign(tf.maximum(self.noise_scale * 0.99, 0.1))  # 노이즈 스케일 감소\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        return {\"loss\": total_loss, \"perceptual_loss\": perceptual_loss, \"kl_loss\": kl_loss}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, y = data\n",
        "        z_mean, z_log_var, z = self.encoder(x, training=False)\n",
        "        reconstruction = self.decoder(z, training=False)\n",
        "\n",
        "        # Perceptual Loss 계산\n",
        "        batch_size, time_steps, height, width, channels = reconstruction.shape\n",
        "        y_reshaped = tf.reshape(y, [batch_size * time_steps, height, width, channels])\n",
        "        reconstruction_reshaped = tf.reshape(reconstruction, [batch_size * time_steps, height, width, channels])\n",
        "        y_features = self.perceptual_model(y_reshaped)\n",
        "        reconstruction_features = self.perceptual_model(reconstruction_reshaped)\n",
        "        perceptual_loss = self.mse_loss(y_features, reconstruction_features)\n",
        "\n",
        "        # KL Loss 계산\n",
        "        beta = 4.0\n",
        "        kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "        kl_loss = beta * tf.clip_by_value(kl_loss, 0, 5000)\n",
        "\n",
        "        total_loss = perceptual_loss + self.kl_weight * kl_loss\n",
        "        return {\"val_loss\": total_loss, \"val_perceptual_loss\": perceptual_loss, \"val_kl_loss\": kl_loss}"
      ],
      "metadata": {
        "id": "Myk3X6Mz6QyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = build_encoder(img_shape=(img_size[0], img_size[1], 3), latent_dim=latent_dim)\n",
        "decoder = build_decoder(latent_dim=latent_dim, output_shape=(fixed_length, img_size[0], img_size[1], 3))\n",
        "cvae = CVAE(encoder, decoder)\n",
        "\n",
        "# compile()에 더미 손실 설정\n",
        "cvae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=lambda y_true, y_pred: 0.0, run_eagerly=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# KL 가중치 스케줄러 인스턴스\n",
        "kl_scheduler = KLDivergenceWeightScheduler()\n",
        "\n",
        "# EarlyStopping 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, min_delta=0.001, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "HRPIxabjf9v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드 및 분할\n",
        "gif_dir = '/content/gifs'\n",
        "gif_paths = [os.path.join(gif_dir, f) for f in os.listdir(gif_dir) if f.endswith('.gif')]\n",
        "\n",
        "train_paths, val_paths = train_test_split(gif_paths, test_size=0.2, random_state=42)\n",
        "x_train, y_train = load_gif_dataset(train_paths, img_size=img_size)\n",
        "x_val, y_val = load_gif_dataset(val_paths, img_size=img_size)\n",
        "\n",
        "# 데이터셋 형태 출력\n",
        "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(2)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgJuXm5-69K4",
        "outputId": "e4f9190a-c176-463b-f611-8d6dbc3b52bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (23, 128, 128, 3), y_train shape: (23, 10, 128, 128, 3)\n",
            "x_val shape: (6, 128, 128, 3), y_val shape: (6, 10, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "cvae.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=200,\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEbqT9R1zw9D",
        "outputId": "3234bf5e-d209-4a12-8dc3-5e115cb54f29",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - kl_loss: 0.0079 - loss: 1.1000 - perceptual_loss: 1.1000 - val_val_kl_loss: 0.0083 - val_val_loss: 1.1812 - val_val_perceptual_loss: 1.1812 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 0.0124 - loss: 1.0997 - perceptual_loss: 1.0997 - val_val_kl_loss: 0.0257 - val_val_loss: 1.1807 - val_val_perceptual_loss: 1.1807 - learning_rate: 1.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 0.3183 - loss: 1.0985 - perceptual_loss: 1.0985 - val_val_kl_loss: 1.4765 - val_val_loss: 1.1779 - val_val_perceptual_loss: 1.1779 - learning_rate: 1.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 10.3858 - loss: 1.0913 - perceptual_loss: 1.0912 - val_val_kl_loss: 30.8692 - val_val_loss: 1.1642 - val_val_perceptual_loss: 1.1640 - learning_rate: 1.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 90.3496 - loss: 1.0635 - perceptual_loss: 1.0629 - val_val_kl_loss: 172.1802 - val_val_loss: 1.1161 - val_val_perceptual_loss: 1.1149 - learning_rate: 1.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 176.8065 - loss: 1.0275 - perceptual_loss: 1.0261 - val_val_kl_loss: 190.9143 - val_val_loss: 1.0845 - val_val_perceptual_loss: 1.0829 - learning_rate: 1.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 195.1673 - loss: 1.0039 - perceptual_loss: 1.0021 - val_val_kl_loss: 243.5300 - val_val_loss: 1.0507 - val_val_perceptual_loss: 1.0484 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 259.6971 - loss: 0.9732 - perceptual_loss: 0.9706 - val_val_kl_loss: 346.5619 - val_val_loss: 1.0126 - val_val_perceptual_loss: 1.0090 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 325.8355 - loss: 0.9366 - perceptual_loss: 0.9330 - val_val_kl_loss: 398.6422 - val_val_loss: 0.9698 - val_val_perceptual_loss: 0.9651 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 363.8961 - loss: 0.8963 - perceptual_loss: 0.8918 - val_val_kl_loss: 418.7193 - val_val_loss: 0.9247 - val_val_perceptual_loss: 0.9193 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 375.0817 - loss: 0.8623 - perceptual_loss: 0.8572 - val_val_kl_loss: 435.5877 - val_val_loss: 0.8904 - val_val_perceptual_loss: 0.8842 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 380.6905 - loss: 0.8423 - perceptual_loss: 0.8366 - val_val_kl_loss: 421.7498 - val_val_loss: 0.8588 - val_val_perceptual_loss: 0.8523 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 385.2656 - loss: 0.8089 - perceptual_loss: 0.8027 - val_val_kl_loss: 427.4425 - val_val_loss: 0.8255 - val_val_perceptual_loss: 0.8184 - learning_rate: 1.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 389.1177 - loss: 0.7837 - perceptual_loss: 0.7771 - val_val_kl_loss: 433.7994 - val_val_loss: 0.8071 - val_val_perceptual_loss: 0.7994 - learning_rate: 1.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 379.8138 - loss: 0.7585 - perceptual_loss: 0.7515 - val_val_kl_loss: 413.5562 - val_val_loss: 0.7894 - val_val_perceptual_loss: 0.7815 - learning_rate: 1.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 357.7458 - loss: 0.7386 - perceptual_loss: 0.7316 - val_val_kl_loss: 411.0558 - val_val_loss: 0.7800 - val_val_perceptual_loss: 0.7717 - learning_rate: 1.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 344.9781 - loss: 0.7273 - perceptual_loss: 0.7202 - val_val_kl_loss: 392.7101 - val_val_loss: 0.7563 - val_val_perceptual_loss: 0.7479 - learning_rate: 1.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 329.6150 - loss: 0.7101 - perceptual_loss: 0.7029 - val_val_kl_loss: 372.6656 - val_val_loss: 0.7299 - val_val_perceptual_loss: 0.7215 - learning_rate: 1.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 318.6436 - loss: 0.6988 - perceptual_loss: 0.6914 - val_val_kl_loss: 359.8652 - val_val_loss: 0.7209 - val_val_perceptual_loss: 0.7123 - learning_rate: 1.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 319.2395 - loss: 0.6861 - perceptual_loss: 0.6783 - val_val_kl_loss: 358.7377 - val_val_loss: 0.7124 - val_val_perceptual_loss: 0.7035 - learning_rate: 1.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 311.5063 - loss: 0.6735 - perceptual_loss: 0.6655 - val_val_kl_loss: 355.6124 - val_val_loss: 0.7059 - val_val_perceptual_loss: 0.6966 - learning_rate: 1.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 311.3117 - loss: 0.6660 - perceptual_loss: 0.6576 - val_val_kl_loss: 357.0785 - val_val_loss: 0.6924 - val_val_perceptual_loss: 0.6826 - learning_rate: 1.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 309.3037 - loss: 0.6602 - perceptual_loss: 0.6515 - val_val_kl_loss: 351.4867 - val_val_loss: 0.6830 - val_val_perceptual_loss: 0.6729 - learning_rate: 1.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 300.8454 - loss: 0.6541 - perceptual_loss: 0.6454 - val_val_kl_loss: 342.1269 - val_val_loss: 0.6756 - val_val_perceptual_loss: 0.6654 - learning_rate: 1.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 294.4959 - loss: 0.6456 - perceptual_loss: 0.6366 - val_val_kl_loss: 338.3466 - val_val_loss: 0.6737 - val_val_perceptual_loss: 0.6632 - learning_rate: 1.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 290.2145 - loss: 0.6444 - perceptual_loss: 0.6352 - val_val_kl_loss: 325.3681 - val_val_loss: 0.6679 - val_val_perceptual_loss: 0.6574 - learning_rate: 1.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 283.9305 - loss: 0.6315 - perceptual_loss: 0.6222 - val_val_kl_loss: 334.0846 - val_val_loss: 0.6638 - val_val_perceptual_loss: 0.6526 - learning_rate: 1.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 275.0573 - loss: 0.6278 - perceptual_loss: 0.6185 - val_val_kl_loss: 319.6378 - val_val_loss: 0.6487 - val_val_perceptual_loss: 0.6376 - learning_rate: 1.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 273.7063 - loss: 0.6208 - perceptual_loss: 0.6111 - val_val_kl_loss: 311.2595 - val_val_loss: 0.6549 - val_val_perceptual_loss: 0.6438 - learning_rate: 1.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 265.0877 - loss: 0.6137 - perceptual_loss: 0.6040 - val_val_kl_loss: 307.4122 - val_val_loss: 0.6569 - val_val_perceptual_loss: 0.6455 - learning_rate: 1.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 255.9622 - loss: 0.6127 - perceptual_loss: 0.6031 - val_val_kl_loss: 296.0294 - val_val_loss: 0.6447 - val_val_perceptual_loss: 0.6334 - learning_rate: 1.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 251.7403 - loss: 0.6065 - perceptual_loss: 0.5967 - val_val_kl_loss: 285.0620 - val_val_loss: 0.6397 - val_val_perceptual_loss: 0.6284 - learning_rate: 1.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 248.4452 - loss: 0.6027 - perceptual_loss: 0.5927 - val_val_kl_loss: 286.8657 - val_val_loss: 0.6380 - val_val_perceptual_loss: 0.6263 - learning_rate: 1.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 241.0054 - loss: 0.6010 - perceptual_loss: 0.5911 - val_val_kl_loss: 274.8806 - val_val_loss: 0.6407 - val_val_perceptual_loss: 0.6292 - learning_rate: 1.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 234.5722 - loss: 0.5972 - perceptual_loss: 0.5872 - val_val_kl_loss: 274.7726 - val_val_loss: 0.6351 - val_val_perceptual_loss: 0.6232 - learning_rate: 1.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 232.0745 - loss: 0.5939 - perceptual_loss: 0.5838 - val_val_kl_loss: 265.5384 - val_val_loss: 0.6354 - val_val_perceptual_loss: 0.6237 - learning_rate: 1.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 227.3836 - loss: 0.5898 - perceptual_loss: 0.5796 - val_val_kl_loss: 263.1266 - val_val_loss: 0.6324 - val_val_perceptual_loss: 0.6205 - learning_rate: 1.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 221.5579 - loss: 0.5892 - perceptual_loss: 0.5790 - val_val_kl_loss: 268.4822 - val_val_loss: 0.6341 - val_val_perceptual_loss: 0.6216 - learning_rate: 1.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 217.4476 - loss: 0.5835 - perceptual_loss: 0.5732 - val_val_kl_loss: 270.9385 - val_val_loss: 0.6365 - val_val_perceptual_loss: 0.6235 - learning_rate: 1.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 212.0370 - loss: 0.5869 - perceptual_loss: 0.5766 - val_val_kl_loss: 259.2769 - val_val_loss: 0.6216 - val_val_perceptual_loss: 0.6089 - learning_rate: 1.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 216.2764 - loss: 0.5759 - perceptual_loss: 0.5652 - val_val_kl_loss: 248.8172 - val_val_loss: 0.6216 - val_val_perceptual_loss: 0.6092 - learning_rate: 1.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 205.5579 - loss: 0.5815 - perceptual_loss: 0.5710 - val_val_kl_loss: 253.7487 - val_val_loss: 0.6388 - val_val_perceptual_loss: 0.6258 - learning_rate: 1.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 199.2740 - loss: 0.5760 - perceptual_loss: 0.5657 - val_val_kl_loss: 241.5830 - val_val_loss: 0.6204 - val_val_perceptual_loss: 0.6077 - learning_rate: 1.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 196.7874 - loss: 0.5753 - perceptual_loss: 0.5648 - val_val_kl_loss: 243.3144 - val_val_loss: 0.6270 - val_val_perceptual_loss: 0.6139 - learning_rate: 1.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 192.2958 - loss: 0.5623 - perceptual_loss: 0.5518 - val_val_kl_loss: 227.3961 - val_val_loss: 0.6186 - val_val_perceptual_loss: 0.6061 - learning_rate: 1.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 186.7962 - loss: 0.5668 - perceptual_loss: 0.5564 - val_val_kl_loss: 238.4312 - val_val_loss: 0.6396 - val_val_perceptual_loss: 0.6262 - learning_rate: 1.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 184.9942 - loss: 0.5755 - perceptual_loss: 0.5650 - val_val_kl_loss: 215.2750 - val_val_loss: 0.6214 - val_val_perceptual_loss: 0.6090 - learning_rate: 1.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 184.0326 - loss: 0.5582 - perceptual_loss: 0.5476 - val_val_kl_loss: 230.1332 - val_val_loss: 0.6117 - val_val_perceptual_loss: 0.5982 - learning_rate: 1.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 182.8765 - loss: 0.5705 - perceptual_loss: 0.5596 - val_val_kl_loss: 221.8329 - val_val_loss: 0.6129 - val_val_perceptual_loss: 0.5996 - learning_rate: 1.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 179.0054 - loss: 0.5560 - perceptual_loss: 0.5452 - val_val_kl_loss: 215.3684 - val_val_loss: 0.6109 - val_val_perceptual_loss: 0.5978 - learning_rate: 1.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 181.2291 - loss: 0.5741 - perceptual_loss: 0.5629 - val_val_kl_loss: 194.9307 - val_val_loss: 0.6189 - val_val_perceptual_loss: 0.6068 - learning_rate: 1.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 177.8704 - loss: 0.6084 - perceptual_loss: 0.5972 - val_val_kl_loss: 190.2805 - val_val_loss: 0.6403 - val_val_perceptual_loss: 0.6282 - learning_rate: 1.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 189.0394 - loss: 0.6641 - perceptual_loss: 0.6520 - val_val_kl_loss: 312.8018 - val_val_loss: 0.7371 - val_val_perceptual_loss: 0.7169 - learning_rate: 1.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 174.7047 - loss: 0.5923 - perceptual_loss: 0.5809 - val_val_kl_loss: 233.6670 - val_val_loss: 0.6269 - val_val_perceptual_loss: 0.6115 - learning_rate: 5.0000e-05\n",
            "Epoch 55/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 179.0567 - loss: 0.5683 - perceptual_loss: 0.5564 - val_val_kl_loss: 265.6732 - val_val_loss: 0.6609 - val_val_perceptual_loss: 0.6431 - learning_rate: 5.0000e-05\n",
            "Epoch 56/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 174.8956 - loss: 0.5547 - perceptual_loss: 0.5429 - val_val_kl_loss: 249.1115 - val_val_loss: 0.6433 - val_val_perceptual_loss: 0.6263 - learning_rate: 5.0000e-05\n",
            "Epoch 57/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 174.2878 - loss: 0.5458 - perceptual_loss: 0.5338 - val_val_kl_loss: 255.4694 - val_val_loss: 0.6695 - val_val_perceptual_loss: 0.6517 - learning_rate: 5.0000e-05\n",
            "Epoch 58/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 167.4234 - loss: 0.5367 - perceptual_loss: 0.5250 - val_val_kl_loss: 249.7009 - val_val_loss: 0.6607 - val_val_perceptual_loss: 0.6431 - learning_rate: 5.0000e-05\n",
            "Epoch 59/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 168.7516 - loss: 0.5293 - perceptual_loss: 0.5172 - val_val_kl_loss: 243.5286 - val_val_loss: 0.6645 - val_val_perceptual_loss: 0.6470 - learning_rate: 5.0000e-05\n",
            "Epoch 60/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 168.2530 - loss: 0.5316 - perceptual_loss: 0.5194 - val_val_kl_loss: 240.2356 - val_val_loss: 0.6735 - val_val_perceptual_loss: 0.6559 - learning_rate: 5.0000e-05\n",
            "Epoch 61/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 162.3545 - loss: 0.5299 - perceptual_loss: 0.5179 - val_val_kl_loss: 243.9764 - val_val_loss: 0.6794 - val_val_perceptual_loss: 0.6613 - learning_rate: 5.0000e-05\n",
            "Epoch 62/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 161.0900 - loss: 0.5215 - perceptual_loss: 0.5094 - val_val_kl_loss: 240.3885 - val_val_loss: 0.6741 - val_val_perceptual_loss: 0.6560 - learning_rate: 5.0000e-05\n",
            "Epoch 63/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 160.9447 - loss: 0.5174 - perceptual_loss: 0.5052 - val_val_kl_loss: 233.4150 - val_val_loss: 0.6573 - val_val_perceptual_loss: 0.6394 - learning_rate: 5.0000e-05\n",
            "Epoch 64/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 159.1213 - loss: 0.5185 - perceptual_loss: 0.5063 - val_val_kl_loss: 230.5354 - val_val_loss: 0.6591 - val_val_perceptual_loss: 0.6412 - learning_rate: 5.0000e-05\n",
            "Epoch 65/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 156.9448 - loss: 0.5177 - perceptual_loss: 0.5054 - val_val_kl_loss: 228.8404 - val_val_loss: 0.6552 - val_val_perceptual_loss: 0.6372 - learning_rate: 5.0000e-05\n",
            "Epoch 66/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 155.7296 - loss: 0.5149 - perceptual_loss: 0.5025 - val_val_kl_loss: 226.6930 - val_val_loss: 0.6545 - val_val_perceptual_loss: 0.6363 - learning_rate: 5.0000e-05\n",
            "Epoch 67/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 155.0118 - loss: 0.5143 - perceptual_loss: 0.5018 - val_val_kl_loss: 223.6303 - val_val_loss: 0.6515 - val_val_perceptual_loss: 0.6333 - learning_rate: 5.0000e-05\n",
            "Epoch 68/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 153.2848 - loss: 0.5155 - perceptual_loss: 0.5030 - val_val_kl_loss: 223.4784 - val_val_loss: 0.6603 - val_val_perceptual_loss: 0.6419 - learning_rate: 5.0000e-05\n",
            "Epoch 69/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 149.6642 - loss: 0.5111 - perceptual_loss: 0.4986 - val_val_kl_loss: 219.0063 - val_val_loss: 0.6441 - val_val_perceptual_loss: 0.6258 - learning_rate: 5.0000e-05\n",
            "Epoch 70/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 150.5937 - loss: 0.5088 - perceptual_loss: 0.4961 - val_val_kl_loss: 217.8204 - val_val_loss: 0.6506 - val_val_perceptual_loss: 0.6321 - learning_rate: 5.0000e-05\n",
            "Epoch 71/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 148.4036 - loss: 0.5070 - perceptual_loss: 0.4943 - val_val_kl_loss: 209.7466 - val_val_loss: 0.6229 - val_val_perceptual_loss: 0.6048 - learning_rate: 5.0000e-05\n",
            "Epoch 72/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 146.5905 - loss: 0.5075 - perceptual_loss: 0.4948 - val_val_kl_loss: 210.5447 - val_val_loss: 0.6501 - val_val_perceptual_loss: 0.6317 - learning_rate: 5.0000e-05\n",
            "Epoch 73/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 145.2194 - loss: 0.5042 - perceptual_loss: 0.4914 - val_val_kl_loss: 206.4043 - val_val_loss: 0.6313 - val_val_perceptual_loss: 0.6131 - learning_rate: 5.0000e-05\n",
            "Epoch 74/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 143.1557 - loss: 0.5017 - perceptual_loss: 0.4890 - val_val_kl_loss: 203.6961 - val_val_loss: 0.6261 - val_val_perceptual_loss: 0.6078 - learning_rate: 5.0000e-05\n",
            "Epoch 75/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 143.7482 - loss: 0.5013 - perceptual_loss: 0.4883 - val_val_kl_loss: 200.8987 - val_val_loss: 0.6231 - val_val_perceptual_loss: 0.6048 - learning_rate: 5.0000e-05\n",
            "Epoch 76/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 141.4584 - loss: 0.5011 - perceptual_loss: 0.4881 - val_val_kl_loss: 200.4006 - val_val_loss: 0.6251 - val_val_perceptual_loss: 0.6066 - learning_rate: 5.0000e-05\n",
            "Epoch 77/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 139.0754 - loss: 0.4961 - perceptual_loss: 0.4832 - val_val_kl_loss: 198.2040 - val_val_loss: 0.6164 - val_val_perceptual_loss: 0.5979 - learning_rate: 5.0000e-05\n",
            "Epoch 78/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 139.3100 - loss: 0.4969 - perceptual_loss: 0.4838 - val_val_kl_loss: 194.0003 - val_val_loss: 0.6217 - val_val_perceptual_loss: 0.6033 - learning_rate: 5.0000e-05\n",
            "Epoch 79/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 138.1109 - loss: 0.4953 - perceptual_loss: 0.4821 - val_val_kl_loss: 192.6480 - val_val_loss: 0.6141 - val_val_perceptual_loss: 0.5956 - learning_rate: 5.0000e-05\n",
            "Epoch 80/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 137.0578 - loss: 0.4930 - perceptual_loss: 0.4798 - val_val_kl_loss: 189.9749 - val_val_loss: 0.6109 - val_val_perceptual_loss: 0.5925 - learning_rate: 5.0000e-05\n",
            "Epoch 81/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 136.6082 - loss: 0.4895 - perceptual_loss: 0.4762 - val_val_kl_loss: 190.5074 - val_val_loss: 0.6107 - val_val_perceptual_loss: 0.5920 - learning_rate: 5.0000e-05\n",
            "Epoch 82/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 135.2455 - loss: 0.4873 - perceptual_loss: 0.4739 - val_val_kl_loss: 189.0151 - val_val_loss: 0.6111 - val_val_perceptual_loss: 0.5923 - learning_rate: 5.0000e-05\n",
            "Epoch 83/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 134.1941 - loss: 0.4831 - perceptual_loss: 0.4697 - val_val_kl_loss: 186.9703 - val_val_loss: 0.6117 - val_val_perceptual_loss: 0.5928 - learning_rate: 5.0000e-05\n",
            "Epoch 84/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 134.0838 - loss: 0.4808 - perceptual_loss: 0.4673 - val_val_kl_loss: 182.4739 - val_val_loss: 0.6021 - val_val_perceptual_loss: 0.5835 - learning_rate: 5.0000e-05\n",
            "Epoch 85/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 133.6439 - loss: 0.4801 - perceptual_loss: 0.4664 - val_val_kl_loss: 180.2363 - val_val_loss: 0.5972 - val_val_perceptual_loss: 0.5786 - learning_rate: 5.0000e-05\n",
            "Epoch 86/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 131.4293 - loss: 0.4795 - perceptual_loss: 0.4659 - val_val_kl_loss: 177.2303 - val_val_loss: 0.5917 - val_val_perceptual_loss: 0.5732 - learning_rate: 5.0000e-05\n",
            "Epoch 87/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 130.2094 - loss: 0.4786 - perceptual_loss: 0.4650 - val_val_kl_loss: 175.1577 - val_val_loss: 0.5888 - val_val_perceptual_loss: 0.5703 - learning_rate: 5.0000e-05\n",
            "Epoch 88/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 128.7589 - loss: 0.4773 - perceptual_loss: 0.4636 - val_val_kl_loss: 174.5333 - val_val_loss: 0.5947 - val_val_perceptual_loss: 0.5761 - learning_rate: 5.0000e-05\n",
            "Epoch 89/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 128.0542 - loss: 0.4747 - perceptual_loss: 0.4610 - val_val_kl_loss: 173.9109 - val_val_loss: 0.5903 - val_val_perceptual_loss: 0.5715 - learning_rate: 5.0000e-05\n",
            "Epoch 90/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 127.0809 - loss: 0.4749 - perceptual_loss: 0.4611 - val_val_kl_loss: 171.0278 - val_val_loss: 0.5896 - val_val_perceptual_loss: 0.5710 - learning_rate: 5.0000e-05\n",
            "Epoch 91/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 125.6858 - loss: 0.4721 - perceptual_loss: 0.4583 - val_val_kl_loss: 168.9962 - val_val_loss: 0.5894 - val_val_perceptual_loss: 0.5708 - learning_rate: 5.0000e-05\n",
            "Epoch 92/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 125.2742 - loss: 0.4709 - perceptual_loss: 0.4570 - val_val_kl_loss: 167.6243 - val_val_loss: 0.5855 - val_val_perceptual_loss: 0.5668 - learning_rate: 5.0000e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 124.3772 - loss: 0.4703 - perceptual_loss: 0.4563 - val_val_kl_loss: 164.8228 - val_val_loss: 0.5797 - val_val_perceptual_loss: 0.5612 - learning_rate: 5.0000e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 122.8550 - loss: 0.4693 - perceptual_loss: 0.4553 - val_val_kl_loss: 165.3194 - val_val_loss: 0.5818 - val_val_perceptual_loss: 0.5630 - learning_rate: 5.0000e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 121.3526 - loss: 0.4682 - perceptual_loss: 0.4544 - val_val_kl_loss: 162.3429 - val_val_loss: 0.5824 - val_val_perceptual_loss: 0.5637 - learning_rate: 5.0000e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 121.3639 - loss: 0.4663 - perceptual_loss: 0.4523 - val_val_kl_loss: 162.0118 - val_val_loss: 0.5796 - val_val_perceptual_loss: 0.5608 - learning_rate: 5.0000e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 120.2991 - loss: 0.4639 - perceptual_loss: 0.4499 - val_val_kl_loss: 161.2405 - val_val_loss: 0.5785 - val_val_perceptual_loss: 0.5596 - learning_rate: 5.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 119.9094 - loss: 0.4641 - perceptual_loss: 0.4500 - val_val_kl_loss: 158.7951 - val_val_loss: 0.5783 - val_val_perceptual_loss: 0.5595 - learning_rate: 5.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 118.6564 - loss: 0.4626 - perceptual_loss: 0.4485 - val_val_kl_loss: 154.3347 - val_val_loss: 0.5704 - val_val_perceptual_loss: 0.5519 - learning_rate: 5.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 117.5734 - loss: 0.4622 - perceptual_loss: 0.4481 - val_val_kl_loss: 153.5138 - val_val_loss: 0.5703 - val_val_perceptual_loss: 0.5518 - learning_rate: 5.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 116.1984 - loss: 0.4613 - perceptual_loss: 0.4472 - val_val_kl_loss: 151.1367 - val_val_loss: 0.5670 - val_val_perceptual_loss: 0.5486 - learning_rate: 5.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 115.5643 - loss: 0.4615 - perceptual_loss: 0.4474 - val_val_kl_loss: 151.1527 - val_val_loss: 0.5705 - val_val_perceptual_loss: 0.5518 - learning_rate: 5.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 113.7682 - loss: 0.4602 - perceptual_loss: 0.4461 - val_val_kl_loss: 148.9869 - val_val_loss: 0.5663 - val_val_perceptual_loss: 0.5478 - learning_rate: 5.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 113.0779 - loss: 0.4593 - perceptual_loss: 0.4451 - val_val_kl_loss: 149.5930 - val_val_loss: 0.5742 - val_val_perceptual_loss: 0.5554 - learning_rate: 5.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 112.4052 - loss: 0.4579 - perceptual_loss: 0.4437 - val_val_kl_loss: 146.0360 - val_val_loss: 0.5697 - val_val_perceptual_loss: 0.5512 - learning_rate: 5.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 111.8126 - loss: 0.4582 - perceptual_loss: 0.4440 - val_val_kl_loss: 144.9685 - val_val_loss: 0.5650 - val_val_perceptual_loss: 0.5465 - learning_rate: 5.0000e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 111.0046 - loss: 0.4575 - perceptual_loss: 0.4433 - val_val_kl_loss: 144.8940 - val_val_loss: 0.5648 - val_val_perceptual_loss: 0.5461 - learning_rate: 5.0000e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 109.5831 - loss: 0.4573 - perceptual_loss: 0.4431 - val_val_kl_loss: 144.8519 - val_val_loss: 0.5714 - val_val_perceptual_loss: 0.5525 - learning_rate: 5.0000e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 109.5940 - loss: 0.4589 - perceptual_loss: 0.4446 - val_val_kl_loss: 144.5662 - val_val_loss: 0.5721 - val_val_perceptual_loss: 0.5531 - learning_rate: 5.0000e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 108.6281 - loss: 0.4600 - perceptual_loss: 0.4456 - val_val_kl_loss: 144.7531 - val_val_loss: 0.5834 - val_val_perceptual_loss: 0.5641 - learning_rate: 5.0000e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 108.6458 - loss: 0.4634 - perceptual_loss: 0.4488 - val_val_kl_loss: 140.1825 - val_val_loss: 0.5725 - val_val_perceptual_loss: 0.5537 - learning_rate: 5.0000e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 107.4094 - loss: 0.4580 - perceptual_loss: 0.4435 - val_val_kl_loss: 142.4756 - val_val_loss: 0.5812 - val_val_perceptual_loss: 0.5620 - learning_rate: 2.5000e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 107.7944 - loss: 0.4489 - perceptual_loss: 0.4343 - val_val_kl_loss: 139.8619 - val_val_loss: 0.5659 - val_val_perceptual_loss: 0.5467 - learning_rate: 2.5000e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 107.5738 - loss: 0.4454 - perceptual_loss: 0.4306 - val_val_kl_loss: 138.6604 - val_val_loss: 0.5610 - val_val_perceptual_loss: 0.5419 - learning_rate: 2.5000e-05\n",
            "Epoch 115/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 106.4250 - loss: 0.4441 - perceptual_loss: 0.4293 - val_val_kl_loss: 139.4706 - val_val_loss: 0.5630 - val_val_perceptual_loss: 0.5436 - learning_rate: 2.5000e-05\n",
            "Epoch 116/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 106.2588 - loss: 0.4426 - perceptual_loss: 0.4278 - val_val_kl_loss: 139.2101 - val_val_loss: 0.5656 - val_val_perceptual_loss: 0.5460 - learning_rate: 2.5000e-05\n",
            "Epoch 117/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 107.2765 - loss: 0.4418 - perceptual_loss: 0.4267 - val_val_kl_loss: 138.1440 - val_val_loss: 0.5585 - val_val_perceptual_loss: 0.5390 - learning_rate: 2.5000e-05\n",
            "Epoch 118/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 105.7860 - loss: 0.4404 - perceptual_loss: 0.4254 - val_val_kl_loss: 138.8398 - val_val_loss: 0.5602 - val_val_perceptual_loss: 0.5404 - learning_rate: 2.5000e-05\n",
            "Epoch 119/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 105.6103 - loss: 0.4403 - perceptual_loss: 0.4252 - val_val_kl_loss: 139.2108 - val_val_loss: 0.5604 - val_val_perceptual_loss: 0.5404 - learning_rate: 2.5000e-05\n",
            "Epoch 120/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 105.3960 - loss: 0.4396 - perceptual_loss: 0.4243 - val_val_kl_loss: 138.4017 - val_val_loss: 0.5554 - val_val_perceptual_loss: 0.5354 - learning_rate: 2.5000e-05\n",
            "Epoch 121/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 105.2787 - loss: 0.4389 - perceptual_loss: 0.4235 - val_val_kl_loss: 136.1967 - val_val_loss: 0.5563 - val_val_perceptual_loss: 0.5364 - learning_rate: 2.5000e-05\n",
            "Epoch 122/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 105.2855 - loss: 0.4380 - perceptual_loss: 0.4225 - val_val_kl_loss: 136.0681 - val_val_loss: 0.5583 - val_val_perceptual_loss: 0.5383 - learning_rate: 2.5000e-05\n",
            "Epoch 123/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 103.9298 - loss: 0.4371 - perceptual_loss: 0.4217 - val_val_kl_loss: 135.8758 - val_val_loss: 0.5532 - val_val_perceptual_loss: 0.5330 - learning_rate: 2.5000e-05\n",
            "Epoch 124/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 104.0396 - loss: 0.4363 - perceptual_loss: 0.4208 - val_val_kl_loss: 134.6874 - val_val_loss: 0.5543 - val_val_perceptual_loss: 0.5342 - learning_rate: 2.5000e-05\n",
            "Epoch 125/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 103.8744 - loss: 0.4355 - perceptual_loss: 0.4199 - val_val_kl_loss: 133.1151 - val_val_loss: 0.5534 - val_val_perceptual_loss: 0.5333 - learning_rate: 2.5000e-05\n",
            "Epoch 126/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 103.7436 - loss: 0.4351 - perceptual_loss: 0.4194 - val_val_kl_loss: 132.4061 - val_val_loss: 0.5525 - val_val_perceptual_loss: 0.5324 - learning_rate: 2.5000e-05\n",
            "Epoch 127/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 102.3363 - loss: 0.4344 - perceptual_loss: 0.4188 - val_val_kl_loss: 132.1141 - val_val_loss: 0.5540 - val_val_perceptual_loss: 0.5337 - learning_rate: 2.5000e-05\n",
            "Epoch 128/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 102.2449 - loss: 0.4339 - perceptual_loss: 0.4181 - val_val_kl_loss: 131.2856 - val_val_loss: 0.5543 - val_val_perceptual_loss: 0.5340 - learning_rate: 2.5000e-05\n",
            "Epoch 129/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 101.7519 - loss: 0.4332 - perceptual_loss: 0.4174 - val_val_kl_loss: 129.0771 - val_val_loss: 0.5505 - val_val_perceptual_loss: 0.5304 - learning_rate: 2.5000e-05\n",
            "Epoch 130/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 101.1952 - loss: 0.4331 - perceptual_loss: 0.4173 - val_val_kl_loss: 131.5832 - val_val_loss: 0.5527 - val_val_perceptual_loss: 0.5321 - learning_rate: 2.5000e-05\n",
            "Epoch 131/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 100.2955 - loss: 0.4321 - perceptual_loss: 0.4163 - val_val_kl_loss: 132.6637 - val_val_loss: 0.5627 - val_val_perceptual_loss: 0.5417 - learning_rate: 2.5000e-05\n",
            "Epoch 132/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 101.0633 - loss: 0.4355 - perceptual_loss: 0.4194 - val_val_kl_loss: 131.5117 - val_val_loss: 0.5603 - val_val_perceptual_loss: 0.5394 - learning_rate: 2.5000e-05\n",
            "Epoch 133/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 101.9494 - loss: 0.4332 - perceptual_loss: 0.4169 - val_val_kl_loss: 124.6963 - val_val_loss: 0.5458 - val_val_perceptual_loss: 0.5258 - learning_rate: 2.5000e-05\n",
            "Epoch 134/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 100.7771 - loss: 0.4341 - perceptual_loss: 0.4178 - val_val_kl_loss: 126.2561 - val_val_loss: 0.5464 - val_val_perceptual_loss: 0.5259 - learning_rate: 2.5000e-05\n",
            "Epoch 135/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 98.8648 - loss: 0.4342 - perceptual_loss: 0.4182 - val_val_kl_loss: 129.9646 - val_val_loss: 0.5569 - val_val_perceptual_loss: 0.5357 - learning_rate: 2.5000e-05\n",
            "Epoch 136/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 98.5082 - loss: 0.4300 - perceptual_loss: 0.4139 - val_val_kl_loss: 129.0807 - val_val_loss: 0.5521 - val_val_perceptual_loss: 0.5309 - learning_rate: 2.5000e-05\n",
            "Epoch 137/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 99.2469 - loss: 0.4292 - perceptual_loss: 0.4128 - val_val_kl_loss: 127.7234 - val_val_loss: 0.5525 - val_val_perceptual_loss: 0.5314 - learning_rate: 2.5000e-05\n",
            "Epoch 138/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 99.5298 - loss: 0.4275 - perceptual_loss: 0.4110 - val_val_kl_loss: 124.5776 - val_val_loss: 0.5457 - val_val_perceptual_loss: 0.5249 - learning_rate: 2.5000e-05\n",
            "Epoch 139/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 98.1653 - loss: 0.4261 - perceptual_loss: 0.4097 - val_val_kl_loss: 124.9406 - val_val_loss: 0.5469 - val_val_perceptual_loss: 0.5259 - learning_rate: 2.5000e-05\n",
            "Epoch 140/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 98.0858 - loss: 0.4247 - perceptual_loss: 0.4082 - val_val_kl_loss: 124.6946 - val_val_loss: 0.5510 - val_val_perceptual_loss: 0.5299 - learning_rate: 2.5000e-05\n",
            "Epoch 141/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 97.9228 - loss: 0.4238 - perceptual_loss: 0.4072 - val_val_kl_loss: 124.7254 - val_val_loss: 0.5488 - val_val_perceptual_loss: 0.5276 - learning_rate: 2.5000e-05\n",
            "Epoch 142/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 97.8559 - loss: 0.4226 - perceptual_loss: 0.4059 - val_val_kl_loss: 124.0123 - val_val_loss: 0.5490 - val_val_perceptual_loss: 0.5277 - learning_rate: 2.5000e-05\n",
            "Epoch 143/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 97.8952 - loss: 0.4220 - perceptual_loss: 0.4052 - val_val_kl_loss: 123.4616 - val_val_loss: 0.5485 - val_val_perceptual_loss: 0.5271 - learning_rate: 2.5000e-05\n",
            "Epoch 144/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 97.4092 - loss: 0.4207 - perceptual_loss: 0.4039 - val_val_kl_loss: 123.0134 - val_val_loss: 0.5532 - val_val_perceptual_loss: 0.5318 - learning_rate: 2.5000e-05\n",
            "Epoch 145/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 96.0482 - loss: 0.4204 - perceptual_loss: 0.4036 - val_val_kl_loss: 120.8956 - val_val_loss: 0.5399 - val_val_perceptual_loss: 0.5188 - learning_rate: 2.5000e-05\n",
            "Epoch 146/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 97.2423 - loss: 0.4193 - perceptual_loss: 0.4022 - val_val_kl_loss: 122.0412 - val_val_loss: 0.5459 - val_val_perceptual_loss: 0.5244 - learning_rate: 2.5000e-05\n",
            "Epoch 147/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 96.4795 - loss: 0.4182 - perceptual_loss: 0.4012 - val_val_kl_loss: 120.2566 - val_val_loss: 0.5428 - val_val_perceptual_loss: 0.5215 - learning_rate: 2.5000e-05\n",
            "Epoch 148/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 96.2844 - loss: 0.4167 - perceptual_loss: 0.3995 - val_val_kl_loss: 120.3612 - val_val_loss: 0.5449 - val_val_perceptual_loss: 0.5234 - learning_rate: 2.5000e-05\n",
            "Epoch 149/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 96.2274 - loss: 0.4161 - perceptual_loss: 0.3988 - val_val_kl_loss: 119.5674 - val_val_loss: 0.5430 - val_val_perceptual_loss: 0.5215 - learning_rate: 2.5000e-05\n",
            "Epoch 150/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 95.8394 - loss: 0.4158 - perceptual_loss: 0.3985 - val_val_kl_loss: 119.7055 - val_val_loss: 0.5437 - val_val_perceptual_loss: 0.5221 - learning_rate: 2.5000e-05\n",
            "Epoch 151/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 94.3390 - loss: 0.4149 - perceptual_loss: 0.3978 - val_val_kl_loss: 120.3078 - val_val_loss: 0.5477 - val_val_perceptual_loss: 0.5258 - learning_rate: 2.5000e-05\n",
            "Epoch 152/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 94.8614 - loss: 0.4147 - perceptual_loss: 0.3974 - val_val_kl_loss: 118.5450 - val_val_loss: 0.5450 - val_val_perceptual_loss: 0.5233 - learning_rate: 2.5000e-05\n",
            "Epoch 153/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 93.9008 - loss: 0.4128 - perceptual_loss: 0.3955 - val_val_kl_loss: 117.7737 - val_val_loss: 0.5479 - val_val_perceptual_loss: 0.5262 - learning_rate: 2.5000e-05\n",
            "Epoch 154/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 94.3174 - loss: 0.4124 - perceptual_loss: 0.3950 - val_val_kl_loss: 115.5113 - val_val_loss: 0.5409 - val_val_perceptual_loss: 0.5194 - learning_rate: 2.5000e-05\n",
            "Epoch 155/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 94.6466 - loss: 0.4111 - perceptual_loss: 0.3934 - val_val_kl_loss: 116.4333 - val_val_loss: 0.5438 - val_val_perceptual_loss: 0.5220 - learning_rate: 2.5000e-05\n",
            "Epoch 156/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 93.8991 - loss: 0.4099 - perceptual_loss: 0.3923 - val_val_kl_loss: 113.6760 - val_val_loss: 0.5401 - val_val_perceptual_loss: 0.5187 - learning_rate: 2.5000e-05\n",
            "Epoch 157/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 93.5516 - loss: 0.4083 - perceptual_loss: 0.3906 - val_val_kl_loss: 113.6150 - val_val_loss: 0.5382 - val_val_perceptual_loss: 0.5166 - learning_rate: 2.5000e-05\n",
            "Epoch 158/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - kl_loss: 94.0534 - loss: 0.4075 - perceptual_loss: 0.3896 - val_val_kl_loss: 115.3533 - val_val_loss: 0.5496 - val_val_perceptual_loss: 0.5276 - learning_rate: 2.5000e-05\n",
            "Epoch 159/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 94.1234 - loss: 0.4059 - perceptual_loss: 0.3880 - val_val_kl_loss: 114.8432 - val_val_loss: 0.5425 - val_val_perceptual_loss: 0.5205 - learning_rate: 2.5000e-05\n",
            "Epoch 160/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 94.0258 - loss: 0.4043 - perceptual_loss: 0.3862 - val_val_kl_loss: 115.6830 - val_val_loss: 0.5508 - val_val_perceptual_loss: 0.5285 - learning_rate: 2.5000e-05\n",
            "Epoch 161/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 93.9517 - loss: 0.4032 - perceptual_loss: 0.3850 - val_val_kl_loss: 113.1028 - val_val_loss: 0.5398 - val_val_perceptual_loss: 0.5178 - learning_rate: 2.5000e-05\n",
            "Epoch 162/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 93.3995 - loss: 0.4011 - perceptual_loss: 0.3829 - val_val_kl_loss: 111.2779 - val_val_loss: 0.5394 - val_val_perceptual_loss: 0.5177 - learning_rate: 2.5000e-05\n",
            "Epoch 163/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 92.9618 - loss: 0.3997 - perceptual_loss: 0.3815 - val_val_kl_loss: 110.6796 - val_val_loss: 0.5349 - val_val_perceptual_loss: 0.5131 - learning_rate: 2.5000e-05\n",
            "Epoch 164/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 94.1101 - loss: 0.3993 - perceptual_loss: 0.3808 - val_val_kl_loss: 109.5000 - val_val_loss: 0.5347 - val_val_perceptual_loss: 0.5130 - learning_rate: 2.5000e-05\n",
            "Epoch 165/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 92.3435 - loss: 0.3972 - perceptual_loss: 0.3789 - val_val_kl_loss: 110.0770 - val_val_loss: 0.5374 - val_val_perceptual_loss: 0.5155 - learning_rate: 2.5000e-05\n",
            "Epoch 166/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 92.9691 - loss: 0.3964 - perceptual_loss: 0.3778 - val_val_kl_loss: 108.5022 - val_val_loss: 0.5281 - val_val_perceptual_loss: 0.5064 - learning_rate: 2.5000e-05\n",
            "Epoch 167/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 92.3930 - loss: 0.3945 - perceptual_loss: 0.3759 - val_val_kl_loss: 106.5798 - val_val_loss: 0.5234 - val_val_perceptual_loss: 0.5019 - learning_rate: 2.5000e-05\n",
            "Epoch 168/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 92.9999 - loss: 0.3945 - perceptual_loss: 0.3757 - val_val_kl_loss: 106.6007 - val_val_loss: 0.5300 - val_val_perceptual_loss: 0.5084 - learning_rate: 2.5000e-05\n",
            "Epoch 169/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 91.5542 - loss: 0.3934 - perceptual_loss: 0.3748 - val_val_kl_loss: 104.3282 - val_val_loss: 0.5244 - val_val_perceptual_loss: 0.5031 - learning_rate: 2.5000e-05\n",
            "Epoch 170/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 91.7169 - loss: 0.3928 - perceptual_loss: 0.3741 - val_val_kl_loss: 105.2489 - val_val_loss: 0.5435 - val_val_perceptual_loss: 0.5220 - learning_rate: 2.5000e-05\n",
            "Epoch 171/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 91.5361 - loss: 0.3919 - perceptual_loss: 0.3731 - val_val_kl_loss: 105.2853 - val_val_loss: 0.5354 - val_val_perceptual_loss: 0.5137 - learning_rate: 2.5000e-05\n",
            "Epoch 172/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 91.5162 - loss: 0.3902 - perceptual_loss: 0.3713 - val_val_kl_loss: 106.5141 - val_val_loss: 0.5377 - val_val_perceptual_loss: 0.5156 - learning_rate: 2.5000e-05\n",
            "Epoch 173/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 91.2893 - loss: 0.3881 - perceptual_loss: 0.3691 - val_val_kl_loss: 107.0875 - val_val_loss: 0.5466 - val_val_perceptual_loss: 0.5242 - learning_rate: 2.5000e-05\n",
            "Epoch 174/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 91.2923 - loss: 0.3899 - perceptual_loss: 0.3708 - val_val_kl_loss: 108.2280 - val_val_loss: 0.5487 - val_val_perceptual_loss: 0.5260 - learning_rate: 2.5000e-05\n",
            "Epoch 175/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 90.8370 - loss: 0.3899 - perceptual_loss: 0.3708 - val_val_kl_loss: 108.5377 - val_val_loss: 0.5740 - val_val_perceptual_loss: 0.5511 - learning_rate: 2.5000e-05\n",
            "Epoch 176/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 91.9300 - loss: 0.3897 - perceptual_loss: 0.3702 - val_val_kl_loss: 101.7171 - val_val_loss: 0.5379 - val_val_perceptual_loss: 0.5163 - learning_rate: 1.2500e-05\n",
            "Epoch 177/200\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - kl_loss: 92.1115 - loss: 0.3832 - perceptual_loss: 0.3636 - val_val_kl_loss: 102.1408 - val_val_loss: 0.5358 - val_val_perceptual_loss: 0.5140 - learning_rate: 1.2500e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bfaab190520>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_frames_from_png(png_path, frame_count=10, latent_dim=32, variation_scale=0.1):\n",
        "    # PNG 파일을 불러와서 크기 조정 및 정규화\n",
        "    png_img = Image.open(png_path).convert('RGB').resize((128, 128))\n",
        "    png_np = np.array(png_img) / 255.0\n",
        "    png_np = png_np.reshape((1, 128, 128, 3))  # 첫 번째 프레임 형식으로 맞춤\n",
        "\n",
        "    # 인코더를 통해 잠재 벡터 생성\n",
        "    z_mean, z_log_var, _ = encoder.predict(png_np)\n",
        "\n",
        "    # 각 프레임을 생성하기 위해 잠재 벡터에 가우시안 노이즈 추가\n",
        "    frames = []\n",
        "    for i in range(frame_count):\n",
        "        # 잠재 공간에서 샘플링하여 새로운 프레임 생성\n",
        "        z_sample = z_mean + np.random.normal(0, variation_scale, size=z_mean.shape)\n",
        "        generated_sequence = decoder.predict(z_sample)  # 시퀀스 형태로 출력됨\n",
        "\n",
        "        # i번째 프레임 선택\n",
        "        if generated_sequence.shape == (1, fixed_length, 128, 128, 3):\n",
        "            frame = generated_sequence[0, i % fixed_length]  # 시퀀스의 i번째 프레임\n",
        "        else:\n",
        "            frame = np.zeros((128, 128, 3))\n",
        "\n",
        "        # 프레임을 [0, 255] 범위로 변환 및 uint8로 캐스팅\n",
        "        frame = (frame * 255).astype(np.uint8)\n",
        "        frames.append(Image.fromarray(frame))\n",
        "\n",
        "    return frames\n"
      ],
      "metadata": {
        "id": "6gn8qY-q6TnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_gif(frames, output_path, duration=100):\n",
        "    frames[0].save(output_path, save_all=True, append_images=frames[1:], loop=0, duration=duration)"
      ],
      "metadata": {
        "id": "8rRowrlS6UuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 예시 호출\n",
        "frames = generate_frames_from_png('/content/93000.png', frame_count=10)\n",
        "save_gif(frames, '/content/93000.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL0gwzqp6Xsg",
        "outputId": "2afcf184-b9c4-443a-d710-d31cdf1d80f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf '/content/frames'\n",
        "# !rm '/content/93000.gif'\n",
        "# !rm '/content/band.gif'\n",
        "# !rm '/content/black.gif'\n",
        "# !rm '/content/pink.gif'"
      ],
      "metadata": {
        "id": "0LGq664l4-Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 파일 다운받기\n",
        "# !zip -r '/content/frames.zip' '/content/frames'\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(\"/content/frames.zip\")"
      ],
      "metadata": {
        "id": "uBhNXkls7DNQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "cvae.save(\"cvae_model.h5\")\n",
        "\n",
        "# 저장된 모델 로드\n",
        "cvae_loaded = load_model(\"cvae_model.h5\", custom_objects={\"KLDivergenceWeightScheduler\": KLDivergenceWeightScheduler})\n",
        "\n",
        "# 로드한 모델을 사용하여 예측\n",
        "frames = generate_frames_from_png(\"/content/93000.png\", frame_count=10, latent_dim=32, variation_scale=1)"
      ],
      "metadata": {
        "id": "B-jM9lQ9UhRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder.save(\"encoder_model.h5\")\n",
        "# decoder.save(\"decoder_model.h5\")\n",
        "\n",
        "# # 인코더와 디코더 로드\n",
        "# encoder_loaded = load_model(\"encoder_model.h5\")\n",
        "# decoder_loaded = load_model(\"decoder_model.h5\")\n",
        "\n",
        "# # 로드된 인코더와 디코더로 CVAE 인스턴스 생성\n",
        "# cvae_loaded = CVAE(encoder_loaded, decoder_loaded)\n",
        "# cvae_loaded.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=lambda y_true, y_pred: 0.0, run_eagerly=True)\n",
        "\n",
        "# # 로드된 인코더 및 디코더를 사용하여 예측\n",
        "# frames = generate_frames_from_png(\"path/to/image.png\", frame_count=10, latent_dim=32, variation_scale=1)"
      ],
      "metadata": {
        "id": "90vRlLe9Uz1i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}